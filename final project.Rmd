---
title: "Final fit"
author: "Kathryn Denning"
date: "6/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading packages}
library(tidyverse)
library(tidymodels)
library(skimr)
library(doParallel)
library(tictoc)
library(vip)
library(xgboost)
library(rio)
```

```{r importing data}
set.seed(2000)
full_train <- read_csv(here::here("data", "train.csv"))  %>% 
    select(-classification)  %>% 
    sample_frac(.01)

frl <- import("https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip",
              setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  select(ncessch, lunch_program, student_count)  %>% 
  mutate(student_count = replace_na(student_count, 0))  %>% 
  pivot_wider(names_from = lunch_program,
              values_from = student_count)  %>% 
  janitor::clean_names()  %>% 
  mutate(ncessch = as.double(ncessch))

stu_counts <- import("https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv",
                     setclass = "tbl_df")  %>% 
  filter(state == "OR" & year == 1718)  %>% 
  count(ncessch, wt = n)  %>% 
  mutate(ncessch = as.double(ncessch))

frl <- left_join(frl, stu_counts)
frl
```

```{r proportions}
frl <- frl  %>% 
    mutate(prop_free = (free_lunch_qualified/n),
           prop_reduce = reduced_price_lunch_qualified/n)

frl
```

```{r merging data}
data <- left_join(full_train, frl, join_by = ncessch)

head(data)
```

```{r splitting data}
splt <- initial_split(data)
train <- training(splt)
cv <- vfold_cv(train)

```

```{r recipe}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %>% 
  step_novel(all_nominal()) %>% 
  step_unknown(all_nominal()) %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% 
  step_dummy(all_nominal(), -has_role("id vars")) %>% 
  step_nzv(all_predictors())

# our old recipe
rec3 <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>%
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% 
  step_novel(all_nominal()) %>%
  step_unknown(all_nominal()) %>% 
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0)  %>% 
  step_dummy(all_nominal())  %>% 
  step_nzv(all_predictors())
```

```{r model}
mod <- boost_tree() %>% 
  set_engine("xgboost", nthreads = parallel::detectCores()) %>% 
  set_mode("regression") 

```

```{r workflow}
wf_df <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(mod)

```

```{r running model 1}
tic()
fit1 <- fit_resamples(wf_df, cv)
toc()
```

```{r metrics fit1}
collect_metrics(fit1)
```

```{r model2}
tune_lr <- mod %>% 
  set_args(trees = 6000,
           learn_rate = tune(),
           stop_iter = 20,
           validation = 0.2)

wf_tune_lr <- wf_df %>% 
  update_model(tune_lr)

grd <- expand.grid(learn_rate = seq(0.005, 0.3, length.out = 15))

tic()
tune_tree_lr <- tune_grid(wf_tune_lr, cv, grid = grd, control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()


#control = tune::control_resamples(verbose = TRUE, save_pred = TRUE)

```

```{r metrics fit2}
collect_metrics(tune_tree_lr)

show_best(tune_tree_lr, "rmse")
```

```{r plot}
to_plot <- tune_tree_lr %>% 
  unnest(.metrics) %>% 
  group_by(.metric, learn_rate) %>% 
  summarize(mean = mean(.estimate, na.rm = TRUE)) %>% 
  filter(learn_rate != 0.0001) 

highlight <- to_plot %>% 
  filter(.metric == "rmse" & mean == min(mean)) %>%
  ungroup() %>% 
  select(learn_rate) %>% 
  semi_join(to_plot, .)


```
