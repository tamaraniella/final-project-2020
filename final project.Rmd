---
title: "Final fit"
author: "Kathryn Denning"
date: "6/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
     dev: png
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading packages}
library(tidyverse)
library(tidymodels)
library(skimr)
library(doParallel)
library(tictoc)
library(vip)
library(xgboost)
library(rio)
library(Cairo)
```

```{r importing data}
set.seed(2000)
full_train <- read_csv(here::here("data", "train.csv"))  %>% 
    select(-classification)  %>% 
    sample_frac(.05)

frl <- import("https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip",
              setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  select(ncessch, lunch_program, student_count)  %>% 
  mutate(student_count = replace_na(student_count, 0))  %>% 
  pivot_wider(names_from = lunch_program,
              values_from = student_count)  %>% 
  janitor::clean_names()  %>% 
  mutate(ncessch = as.double(ncessch))

stu_counts <- import("https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv",
                     setclass = "tbl_df")  %>% 
  filter(state == "OR" & year == 1718)  %>% 
  count(ncessch, wt = n)  %>% 
  mutate(ncessch = as.double(ncessch))

frl <- left_join(frl, stu_counts)
frl
```

```{r proportions}
frl <- frl  %>% 
    mutate(prop_free = (free_lunch_qualified/n),
           prop_reduce = reduced_price_lunch_qualified/n)

frl
```

```{r merging data}
data <- left_join(full_train, frl, join_by = ncessch)

head(data)
```

```{r splitting data}
splt <- initial_split(data)
train <- training(splt)
cv <- vfold_cv(train)

```

```{r recipe}
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %>% 
  step_novel(all_nominal()) %>% 
  step_unknown(all_nominal()) %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% 
  step_dummy(all_nominal(), -has_role("id vars")) %>% 
  step_nzv(all_predictors())
```

```{r model}
mod <- boost_tree() %>% 
  set_engine("xgboost", nthreads = parallel::detectCores()) %>% 
  set_mode("regression") 

```

```{r workflow}
wf_df <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(mod)

```

```{r running model 1}
tic()
fit1 <- fit_resamples(wf_df, cv)
toc()
```

```{r metrics fit1}
collect_metrics(fit1)
#base model best fit is 100
```

```{r model2}
tune_lr <- mod %>% 
  set_args(trees = 6000,
           learn_rate = tune(),
           stop_iter = 20,
           validation = 0.2)

wf_tune_lr <- wf_df %>% 
  update_model(tune_lr)

grd <- expand.grid(learn_rate = seq(0.005, 0.3, length.out = 15))

tic()
tune_tree_lr <- tune_grid(wf_tune_lr, cv, grid = grd, control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()

#best learning rate from this model was 0.005  rmse    standard   104.       10  2.51  
```

```{r metrics fit2}
collect_metrics(tune_tree_lr)

show_best(tune_tree_lr, "rmse")
```

```{r plot}
to_plot <- tune_tree_lr %>% 
  unnest(.metrics) %>% 
  group_by(.metric, learn_rate) %>% 
  summarize(mean = mean(.estimate, na.rm = TRUE)) %>% 
  filter(learn_rate != 0.0001) 

highlight <- to_plot %>% 
  filter(.metric == "rmse" & mean == min(mean)) %>%
  ungroup() %>% 
  select(learn_rate) %>% 
  semi_join(to_plot, .)

ggplot(to_plot, aes(learn_rate, mean)) +
  geom_point() +
  geom_point(color = "#de4f69", data = highlight) +
  facet_wrap(~.metric, scales = "free_y")

```

```{r find best learn rate}
tune_lr2 <- mod %>% 
  set_args(trees = 6000,
           learn_rate = tune(),
           stop_iter = 20,
           validation = 0.2)

wf_tune_lr <- wf_df %>% 
  update_model(tune_lr2)

grd <- expand.grid(learn_rate = seq(0.0001, 0.1, length.out = 15))

tic()
tune_tree_lr2 <- tune_grid(wf_tune_lr, cv, grid = grd, control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()
```

```{r metrics fit3}
collect_metrics(tune_tree_lr2)

show_best(tune_tree_lr2, "rmse")

#best model had a learn rate of  0.00724 and a rsme of 105
```

```{r plot}
to_plot2 <- tune_tree_lr2 %>% 
  unnest(.metrics) %>% 
  group_by(.metric, learn_rate) %>% 
  summarize(mean = mean(.estimate, na.rm = TRUE)) %>% 
  filter(learn_rate != 0.0001) 

highlight2 <- to_plot2 %>% 
  filter(.metric == "rmse" & mean == min(mean)) %>%
  ungroup() %>% 
  select(learn_rate) %>% 
  semi_join(to_plot, .)

ggplot(to_plot2, aes(learn_rate, mean)) +
  geom_point() +
  geom_point(color = "#de4f69", data = highlight2) +
  facet_wrap(~.metric, scales = "free_y")

```

```{r tuning tree depth}
tune_depth <- tune_lr %>% 
  finalize_model(select_best(tune_tree_lr, "rmse")) %>% 
  set_args(tree_depth = tune(),
           min_n = tune())

wf_tune_depth <- wf_df %>% 
  update_model(tune_depth)

grd <- grid_max_entropy(tree_depth(), min_n(), size = 30)

tic()
tune_tree_depth <- tune_grid(wf_tune_depth, cv, grid = grd, control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()

# best is min n of 38, tree depth of 1, with an rmse of 93.9
```

```{r metrics fit4}
collect_metrics(tune_tree_depth)

show_best(tune_tree_depth, "rmse")

#best model had a depth of 1, min_n of 38 and rmse of 93.9
```

```{r}
autoplot(tune_tree_depth)
```

```{r}
tune_loss <- tune_depth %>% 
  finalize_model(select_best(tune_tree_depth, "rmse")) %>% 
  set_args(loss_reduction = tune(),
           tree_depth = 1)

wf_tune_reg <- wf_df %>% 
  update_model(tune_loss)

grd <- expand.grid(loss_reduction = seq(0, 100, 5))

tic()
tune_tree_reg <- tune_grid(wf_tune_reg, cv, grid = grd, control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()

```

```{r metrics loss model}
collect_metrics(tune_tree_reg)

show_best(tune_tree_reg, "rmse")

# no improvement on last model
```

```{r tuning randomness}
tune_rand <- tune_loss %>%
  finalize_model(select_best(tune_tree_reg, "rmse")) %>% 
  set_args(mtry = tune(),
           sample_size = tune())

wf_tune_rand <- wf_df %>% 
  update_model(tune_rand)

grd <- grid_max_entropy(finalize(mtry(), juice(prep(rec))), 
                        sample_size = sample_prop(), 
                        size = 30)

tic()
tune_tree_rand <- tune_grid(wf_tune_rand, cv, grid = grd,control = tune::control_resamples(verbose = TRUE, save_pred = TRUE))
toc()
```

```{r metrics randomness model}
collect_metrics(tune_tree_rand)

show_best(tune_tree_rand, "rmse")

# best model has an mtry of 20, sample size of 0.762 and mean 93.8

autoplot(tune_tree_rand)

to_plot_rand <- tune_tree_rand %>% 
  unnest(.metrics) %>% 
  group_by(.metric, mtry, sample_size) %>% 
  summarize(mean = mean(.estimate, na.rm = TRUE)) %>% 
  filter(.metric == "rmse") %>%
  ungroup() %>% 
  pivot_longer(cols = c(mtry, sample_size), 
               names_to = "tuning_param", 
               values_to = "tuning_val")

highlight_rand <- to_plot_rand %>% 
  filter(mean == min(mean))
  
ggplot(to_plot_rand, aes(tuning_val, mean)) +
  geom_point() +
  geom_point(color = "#de4f69", data = highlight_rand) +
  facet_wrap(~tuning_param) +
  labs(title = "Mean after tuning randomness using mtry and sample size",
       subtitle = "Best RMSE identified by red point",
       x = "Tuning value")+
  theme_minimal()


```

```{r prepping for predictions}
# Select best tuning parameters
tune_tree_best <- tune_tree_rand %>%
  select_best(metric = "rmse")

# Finalize your model using the best tuning parameters
tune_tree_final <- tune_rand %>%
    finalize_model(tune_tree_best)

rec_tree_final <- rec %>% 
   finalize_recipe(tune_tree_best)

prepped_train <- rec_tree_final  %>% 
  prep() %>% 
  bake(train)  %>% 
  select(-contains("id"), -ncessch)

real_test <- read_csv(here::here("data", "test.csv"), col_types = cols(.default = col_guess(), calc_admn_cd = col_character())) %>% 
  left_join(frl)

prepped_test <- rec_tree_final  %>% 
  prep()  %>%  
  bake(real_test) %>%
  select(-contains("id"), -ncessch)

full_train_fit <- fit(tune_tree_final, score ~ ., prepped_train)

```



```{r predictions}

preds <- predict(full_train_fit, new_data = prepped_test)

pred_file <- tibble(Id = real_test$id, Predicted = preds$.pred) 

write_csv(pred_file, "final_submission.csv")
```